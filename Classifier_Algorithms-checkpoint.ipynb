{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6mOzVpQOHI3"
   },
   "source": [
    "Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "4AF3g_zWLIsx",
    "outputId": "06bcbac0-e48f-4c26-befa-2281b1e37da0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.73      0.73       453\n",
      "           2       0.00      0.00      0.00        77\n",
      "           3       0.04      0.01      0.02        73\n",
      "           4       0.84      0.53      0.65       169\n",
      "           5       0.79      0.91      0.85      1099\n",
      "\n",
      "    accuracy                           0.76      1871\n",
      "   macro avg       0.48      0.44      0.45      1871\n",
      "weighted avg       0.72      0.76      0.73      1871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "train_csv_path = \"D:/embedding_train.csv\"\n",
    "df_train = pd.read_csv(train_csv_path)\n",
    "\n",
    "X_train = np.array([np.load(path).flatten() for path in df_train['numpypath']])\n",
    "y_train = df_train['savepath']\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=10, random_state=42) \n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "test_csv_path = 'D:/embedding_test.csv'\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "X_test = np.array([np.load(path).flatten() for path in df_test['numpypath']])\n",
    "y_test = df_test['savepath']\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "n \n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9dWLhf4OJ_i"
   },
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "RvTxKJUmO4UX",
    "outputId": "1b0b7219-d24c-4c41-ac48-cc3fda9cb633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.65      0.71       453\n",
      "           2       0.00      0.00      0.00        77\n",
      "           3       0.00      0.00      0.00        73\n",
      "           4       0.95      0.53      0.68       169\n",
      "           5       0.74      0.95      0.84      1099\n",
      "\n",
      "    accuracy                           0.76      1871\n",
      "   macro avg       0.50      0.43      0.44      1871\n",
      "weighted avg       0.71      0.76      0.72      1871\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pepperdine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pepperdine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pepperdine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "train_csv_path = \"D:/embedding_train.csv\"\n",
    "df_train = pd.read_csv(train_csv_path)\n",
    "\n",
    "X_train = np.array([np.load(path).flatten() for path in df_train['numpypath']])\n",
    "y_train = df_train['savepath']\n",
    "\n",
    "svm_classifier = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "test_csv_path = 'D:/embedding_test.csv'\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "X_test = np.array([np.load(path).flatten() for path in df_test['numpypath']])\n",
    "y_test = df_test['savepath']\n",
    "\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NAuFC1HvOKxZ"
   },
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4iTAcoW8O9wb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pepperdine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.64      0.65       453\n",
      "           2       0.20      0.03      0.05        77\n",
      "           3       0.00      0.00      0.00        73\n",
      "           4       0.69      0.49      0.57       169\n",
      "           5       0.74      0.88      0.80      1099\n",
      "\n",
      "    accuracy                           0.71      1871\n",
      "   macro avg       0.46      0.40      0.41      1871\n",
      "weighted avg       0.67      0.71      0.68      1871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "   \n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "train_csv_path = \"D:/embedding_train.csv\"\n",
    "df_train = pd.read_csv(train_csv_path)\n",
    "\n",
    "X_train = np.array([np.load(path).flatten() for path in df_train['numpypath']])\n",
    "y_train = df_train['savepath']\n",
    "\n",
    "logistic_regression_model = LogisticRegression(random_state=42)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "test_csv_path = 'D:/embedding_test.csv'\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "X_test = np.array([np.load(path).flatten() for path in df_test['numpypath']])\n",
    "y_test = df_test['savepath']\n",
    "\n",
    "y_pred = logistic_regression_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMJplXLoOLxf"
   },
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "87jMffsoP2Sf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.74      0.70       453\n",
      "           2       0.09      0.03      0.04        77\n",
      "           3       0.02      0.01      0.02        73\n",
      "           4       0.79      0.53      0.63       169\n",
      "           5       0.81      0.88      0.85      1099\n",
      "\n",
      "    accuracy                           0.75      1871\n",
      "   macro avg       0.48      0.44      0.45      1871\n",
      "weighted avg       0.71      0.75      0.73      1871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "train_csv_path = \"D:/embedding_train.csv\"\n",
    "df_train = pd.read_csv(train_csv_path)\n",
    "\n",
    "X_train = np.array([np.load(path).flatten() for path in df_train['numpypath']])\n",
    "y_train = df_train['savepath']\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "test_csv_path = 'D:/embedding_test.csv'\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "X_test = np.array([np.load(path).flatten() for path in df_test['numpypath']])\n",
    "y_test = df_test['savepath']\n",
    "\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8No95U7ONLp"
   },
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "6ViCZk2UOFT1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Shape of X_train: (14961, 12544)\n",
      "Shape of X_test: (1871, 12544)\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.73      0.74       453\n",
      "           2       0.09      0.09      0.09        77\n",
      "           3       0.08      0.05      0.06        73\n",
      "           4       0.83      0.54      0.66       169\n",
      "           5       0.82      0.88      0.85      1099\n",
      "\n",
      "    accuracy                           0.75      1871\n",
      "   macro avg       0.51      0.46      0.48      1871\n",
      "weighted avg       0.74      0.75      0.74      1871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "train_csv_path = \"D:/embedding_train.csv\"\n",
    "df_train = pd.read_csv(train_csv_path)\n",
    "\n",
    "X_train = np.array([np.load(path).flatten() for path in df_train['numpypath']])\n",
    "y_train = df_train['savepath']\n",
    "\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=400, random_state=42)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "\n",
    "test_csv_path = 'D:/embedding_test.csv'\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "X_test = np.array([np.load(path).flatten() for path in df_test['numpypath']])\n",
    "y_test = df_test['savepath']\n",
    "\n",
    "y_pred = mlp_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print the shape of tensors\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the numpy array from the .npy file\n",
    "latent_vector = np.load(r\"D:\\latent_vectors_train\\1.npy\")\n",
    "\n",
    "# Print the dimensions of the array\n",
    "print(latent_vector.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 1.036\n",
      "Epoch: 2 loss: 0.852\n",
      "Epoch: 3 loss: 0.772\n",
      "Epoch: 4 loss: 0.729\n",
      "Epoch: 5 loss: 0.695\n",
      "Epoch: 6 loss: 0.672\n",
      "Epoch: 7 loss: 0.652\n",
      "Epoch: 8 loss: 0.636\n",
      "Epoch: 9 loss: 0.623\n",
      "Epoch: 10 loss: 0.611\n",
      "Finished Training\n",
      "Accuracy: 0.77\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.62      0.72       453\n",
      "           2       0.00      0.00      0.00        77\n",
      "           3       0.00      0.00      0.00        73\n",
      "           4       0.84      0.54      0.66       169\n",
      "           5       0.74      0.96      0.84      1099\n",
      "\n",
      "    accuracy                           0.77      1871\n",
      "   macro avg       0.49      0.43      0.44      1871\n",
      "weighted avg       0.72      0.77      0.73      1871\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pepperdine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pepperdine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pepperdine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# load data\n",
    "train_csv_path = \"D:/embedding_train.csv\"\n",
    "df_train = pd.read_csv(train_csv_path)\n",
    "\n",
    "X_train = torch.stack([torch.from_numpy(np.load(path)).view(16, 28, 28) for path in df_train['numpypath']])\n",
    "y_train = torch.from_numpy(df_train['savepath'].values-1)  # subtract 1 as PyTorch expects classes starting from 0\n",
    "\n",
    "test_csv_path = 'D:/embedding_test.csv'\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "X_test = torch.stack([torch.from_numpy(np.load(path)).view(16, 28, 28) for path in df_test['numpypath']])\n",
    "y_test = torch.from_numpy(df_test['savepath'].values-1)  # subtract 1 as PyTorch expects classes starting from 0\n",
    "\n",
    "# wrap data in dataloaders\n",
    "batch_size = 32\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# define the CNN architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)  # flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# train the model\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('Epoch: %d loss: %.3f' % (epoch + 1, running_loss / len(train_loader)))\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.extend((predicted+1).numpy().tolist()) \n",
    "        y_true.extend((labels+1).numpy().tolist())    \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, digits=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 1.073\n",
      "Epoch: 2 loss: 0.793\n",
      "Epoch: 3 loss: 0.697\n",
      "Epoch: 4 loss: 0.648\n",
      "Epoch: 5 loss: 0.617\n",
      "Epoch: 6 loss: 0.596\n",
      "Epoch: 7 loss: 0.579\n",
      "Epoch: 8 loss: 0.571\n",
      "Epoch: 9 loss: 0.555\n",
      "Epoch: 10 loss: 0.549\n",
      "Epoch: 11 loss: 0.548\n",
      "Epoch: 12 loss: 0.542\n",
      "Epoch: 13 loss: 0.534\n",
      "Epoch: 14 loss: 0.529\n",
      "Epoch: 15 loss: 0.522\n",
      "Epoch: 16 loss: 0.526\n",
      "Epoch: 17 loss: 0.516\n",
      "Epoch: 18 loss: 0.518\n",
      "Epoch: 19 loss: 0.510\n",
      "Epoch: 20 loss: 0.504\n",
      "Finished Training\n",
      "Accuracy: 0.79\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.67      0.78       453\n",
      "           2       0.00      0.00      0.00        77\n",
      "           3       0.00      0.00      0.00        73\n",
      "           4       1.00      0.53      0.69       169\n",
      "           5       0.74      0.99      0.85      1099\n",
      "\n",
      "    accuracy                           0.79      1871\n",
      "   macro avg       0.54      0.44      0.47      1871\n",
      "weighted avg       0.75      0.79      0.75      1871\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pepperdine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pepperdine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pepperdine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# load data\n",
    "train_csv_path = \"C:/Users/Pepperdine/Desktop/datasets/embedding_train - Copy.csv\"\n",
    "df_train = pd.read_csv(train_csv_path)\n",
    "\n",
    "X_train = torch.stack([torch.from_numpy(np.load(path)).view(16, 28, 28) for path in df_train['numpypath']])\n",
    "y_train = torch.from_numpy(df_train['savepath'].values-1)  # subtract 1 as PyTorch expects classes starting from 0\n",
    "\n",
    "test_csv_path = \"C:/Users/Pepperdine/Desktop/datasets/embedding_test - Copy.csv\"\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "X_test = torch.stack([torch.from_numpy(np.load(path)).view(16, 28, 28) for path in df_test['numpypath']])\n",
    "y_test = torch.from_numpy(df_test['savepath'].values-1)  \n",
    "\n",
    "batch_size = 8\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)   \n",
    "        self.fc5 = nn.Linear(64, 32)   \n",
    "        self.fc6 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train the model\n",
    "for epoch in range(20):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('Epoch: %d loss: %.3f' % (epoch + 1, running_loss / len(train_loader)))\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.extend((predicted+1).numpy().tolist())  \n",
    "        y_true.extend((labels+1).numpy().tolist())   \n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if tweaking parameters doesnt work im going to edit the latent vector labels and rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)   # Added one more fully connected layer\n",
    "        self.fc5 = nn.Linear(64, 32)   # Added yet another fully connected layer\n",
    "        self.fc6 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc6(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 187/1871: Loss = 1.165\n",
      "Epoch 1, Batch 374/1871: Loss = 1.172\n",
      "Epoch 1, Batch 561/1871: Loss = 1.189\n",
      "Epoch 1, Batch 748/1871: Loss = 1.185\n",
      "Epoch 1, Batch 935/1871: Loss = 1.184\n",
      "Epoch 1, Batch 1122/1871: Loss = 1.184\n",
      "Epoch 1, Batch 1309/1871: Loss = 1.182\n",
      "Epoch 1, Batch 1496/1871: Loss = 1.180\n",
      "Epoch 1, Batch 1683/1871: Loss = 1.181\n",
      "Epoch 1, Batch 1870/1871: Loss = 1.175\n",
      "Epoch: 1 loss: 1.175\n",
      "Epoch 2, Batch 187/1871: Loss = 1.184\n",
      "Epoch 2, Batch 374/1871: Loss = 1.176\n",
      "Epoch 2, Batch 561/1871: Loss = 1.168\n",
      "Epoch 2, Batch 748/1871: Loss = 1.167\n",
      "Epoch 2, Batch 935/1871: Loss = 1.165\n",
      "Epoch 2, Batch 1122/1871: Loss = 1.171\n",
      "Epoch 2, Batch 1309/1871: Loss = 1.170\n",
      "Epoch 2, Batch 1496/1871: Loss = 1.172\n",
      "Epoch 2, Batch 1683/1871: Loss = 1.172\n",
      "Epoch 2, Batch 1870/1871: Loss = 1.173\n",
      "Epoch: 2 loss: 1.173\n",
      "Epoch 3, Batch 187/1871: Loss = 1.174\n",
      "Epoch 3, Batch 374/1871: Loss = 1.174\n",
      "Epoch 3, Batch 561/1871: Loss = 1.177\n",
      "Epoch 3, Batch 748/1871: Loss = 1.177\n",
      "Epoch 3, Batch 935/1871: Loss = 1.181\n",
      "Epoch 3, Batch 1122/1871: Loss = 1.174\n",
      "Epoch 3, Batch 1309/1871: Loss = 1.176\n",
      "Epoch 3, Batch 1496/1871: Loss = 1.175\n",
      "Epoch 3, Batch 1683/1871: Loss = 1.173\n",
      "Epoch 3, Batch 1870/1871: Loss = 1.173\n",
      "Epoch: 3 loss: 1.174\n",
      "Epoch 4, Batch 187/1871: Loss = 1.137\n",
      "Epoch 4, Batch 374/1871: Loss = 1.166\n",
      "Epoch 4, Batch 561/1871: Loss = 1.179\n",
      "Epoch 4, Batch 748/1871: Loss = 1.175\n",
      "Epoch 4, Batch 935/1871: Loss = 1.170\n",
      "Epoch 4, Batch 1122/1871: Loss = 1.162\n",
      "Epoch 4, Batch 1309/1871: Loss = 1.165\n",
      "Epoch 4, Batch 1496/1871: Loss = 1.168\n",
      "Epoch 4, Batch 1683/1871: Loss = 1.167\n",
      "Epoch 4, Batch 1870/1871: Loss = 1.170\n",
      "Epoch: 4 loss: 1.170\n",
      "Epoch 5, Batch 187/1871: Loss = 1.161\n",
      "Epoch 5, Batch 374/1871: Loss = 1.183\n",
      "Epoch 5, Batch 561/1871: Loss = 1.165\n",
      "Epoch 5, Batch 748/1871: Loss = 1.170\n",
      "Epoch 5, Batch 935/1871: Loss = 1.173\n",
      "Epoch 5, Batch 1122/1871: Loss = 1.173\n",
      "Epoch 5, Batch 1309/1871: Loss = 1.174\n",
      "Epoch 5, Batch 1496/1871: Loss = 1.174\n",
      "Epoch 5, Batch 1683/1871: Loss = 1.176\n",
      "Epoch 5, Batch 1870/1871: Loss = 1.174\n",
      "Epoch: 5 loss: 1.175\n",
      "Epoch 6, Batch 187/1871: Loss = 1.152\n",
      "Epoch 6, Batch 374/1871: Loss = 1.181\n",
      "Epoch 6, Batch 561/1871: Loss = 1.177\n",
      "Epoch 6, Batch 748/1871: Loss = 1.175\n",
      "Epoch 6, Batch 935/1871: Loss = 1.173\n",
      "Epoch 6, Batch 1122/1871: Loss = 1.173\n",
      "Epoch 6, Batch 1309/1871: Loss = 1.171\n",
      "Epoch 6, Batch 1496/1871: Loss = 1.171\n",
      "Epoch 6, Batch 1683/1871: Loss = 1.170\n",
      "Epoch 6, Batch 1870/1871: Loss = 1.174\n",
      "Epoch: 6 loss: 1.173\n",
      "Epoch 7, Batch 187/1871: Loss = 1.173\n",
      "Epoch 7, Batch 374/1871: Loss = 1.189\n",
      "Epoch 7, Batch 561/1871: Loss = 1.183\n",
      "Epoch 7, Batch 748/1871: Loss = 1.179\n",
      "Epoch 7, Batch 935/1871: Loss = 1.168\n",
      "Epoch 7, Batch 1122/1871: Loss = 1.170\n",
      "Epoch 7, Batch 1309/1871: Loss = 1.173\n",
      "Epoch 7, Batch 1496/1871: Loss = 1.174\n",
      "Epoch 7, Batch 1683/1871: Loss = 1.173\n",
      "Epoch 7, Batch 1870/1871: Loss = 1.173\n",
      "Epoch: 7 loss: 1.173\n",
      "Epoch 8, Batch 187/1871: Loss = 1.174\n",
      "Epoch 8, Batch 374/1871: Loss = 1.187\n",
      "Epoch 8, Batch 561/1871: Loss = 1.187\n",
      "Epoch 8, Batch 748/1871: Loss = 1.176\n",
      "Epoch 8, Batch 935/1871: Loss = 1.176\n",
      "Epoch 8, Batch 1122/1871: Loss = 1.173\n",
      "Epoch 8, Batch 1309/1871: Loss = 1.168\n",
      "Epoch 8, Batch 1496/1871: Loss = 1.169\n",
      "Epoch 8, Batch 1683/1871: Loss = 1.168\n",
      "Epoch 8, Batch 1870/1871: Loss = 1.171\n",
      "Epoch: 8 loss: 1.171\n",
      "Epoch 9, Batch 187/1871: Loss = 1.175\n",
      "Epoch 9, Batch 374/1871: Loss = 1.167\n",
      "Epoch 9, Batch 561/1871: Loss = 1.158\n",
      "Epoch 9, Batch 748/1871: Loss = 1.163\n",
      "Epoch 9, Batch 935/1871: Loss = 1.169\n",
      "Epoch 9, Batch 1122/1871: Loss = 1.171\n",
      "Epoch 9, Batch 1309/1871: Loss = 1.172\n",
      "Epoch 9, Batch 1496/1871: Loss = 1.173\n",
      "Epoch 9, Batch 1683/1871: Loss = 1.173\n",
      "Epoch 9, Batch 1870/1871: Loss = 1.174\n",
      "Epoch: 9 loss: 1.174\n",
      "Epoch 10, Batch 187/1871: Loss = 1.169\n",
      "Epoch 10, Batch 374/1871: Loss = 1.191\n",
      "Epoch 10, Batch 561/1871: Loss = 1.199\n",
      "Epoch 10, Batch 748/1871: Loss = 1.180\n",
      "Epoch 10, Batch 935/1871: Loss = 1.176\n",
      "Epoch 10, Batch 1122/1871: Loss = 1.176\n",
      "Epoch 10, Batch 1309/1871: Loss = 1.168\n",
      "Epoch 10, Batch 1496/1871: Loss = 1.170\n",
      "Epoch 10, Batch 1683/1871: Loss = 1.168\n",
      "Epoch 10, Batch 1870/1871: Loss = 1.170\n",
      "Epoch: 10 loss: 1.170\n",
      "Epoch 11, Batch 187/1871: Loss = 1.174\n",
      "Epoch 11, Batch 374/1871: Loss = 1.167\n",
      "Epoch 11, Batch 561/1871: Loss = 1.168\n",
      "Epoch 11, Batch 748/1871: Loss = 1.178\n",
      "Epoch 11, Batch 935/1871: Loss = 1.172\n",
      "Epoch 11, Batch 1122/1871: Loss = 1.174\n",
      "Epoch 11, Batch 1309/1871: Loss = 1.168\n",
      "Epoch 11, Batch 1496/1871: Loss = 1.172\n",
      "Epoch 11, Batch 1683/1871: Loss = 1.172\n",
      "Epoch 11, Batch 1870/1871: Loss = 1.172\n",
      "Epoch: 11 loss: 1.172\n",
      "Epoch 12, Batch 187/1871: Loss = 1.176\n",
      "Epoch 12, Batch 374/1871: Loss = 1.192\n",
      "Epoch 12, Batch 561/1871: Loss = 1.182\n",
      "Epoch 12, Batch 748/1871: Loss = 1.185\n",
      "Epoch 12, Batch 935/1871: Loss = 1.182\n",
      "Epoch 12, Batch 1122/1871: Loss = 1.177\n",
      "Epoch 12, Batch 1309/1871: Loss = 1.177\n",
      "Epoch 12, Batch 1496/1871: Loss = 1.174\n",
      "Epoch 12, Batch 1683/1871: Loss = 1.170\n",
      "Epoch 12, Batch 1870/1871: Loss = 1.171\n",
      "Epoch: 12 loss: 1.171\n",
      "Epoch 13, Batch 187/1871: Loss = 1.162\n",
      "Epoch 13, Batch 374/1871: Loss = 1.176\n",
      "Epoch 13, Batch 561/1871: Loss = 1.193\n",
      "Epoch 13, Batch 748/1871: Loss = 1.191\n",
      "Epoch 13, Batch 935/1871: Loss = 1.189\n",
      "Epoch 13, Batch 1122/1871: Loss = 1.181\n",
      "Epoch 13, Batch 1309/1871: Loss = 1.178\n",
      "Epoch 13, Batch 1496/1871: Loss = 1.178\n",
      "Epoch 13, Batch 1683/1871: Loss = 1.174\n",
      "Epoch 13, Batch 1870/1871: Loss = 1.171\n",
      "Epoch: 13 loss: 1.171\n",
      "Epoch 14, Batch 187/1871: Loss = 1.173\n",
      "Epoch 14, Batch 374/1871: Loss = 1.169\n",
      "Epoch 14, Batch 561/1871: Loss = 1.166\n",
      "Epoch 14, Batch 748/1871: Loss = 1.167\n",
      "Epoch 14, Batch 935/1871: Loss = 1.169\n",
      "Epoch 14, Batch 1122/1871: Loss = 1.166\n",
      "Epoch 14, Batch 1309/1871: Loss = 1.166\n",
      "Epoch 14, Batch 1496/1871: Loss = 1.169\n",
      "Epoch 14, Batch 1683/1871: Loss = 1.168\n",
      "Epoch 14, Batch 1870/1871: Loss = 1.172\n",
      "Epoch: 14 loss: 1.171\n",
      "Epoch 15, Batch 187/1871: Loss = 1.168\n",
      "Epoch 15, Batch 374/1871: Loss = 1.161\n",
      "Epoch 15, Batch 561/1871: Loss = 1.170\n",
      "Epoch 15, Batch 748/1871: Loss = 1.178\n",
      "Epoch 15, Batch 935/1871: Loss = 1.177\n",
      "Epoch 15, Batch 1122/1871: Loss = 1.173\n",
      "Epoch 15, Batch 1309/1871: Loss = 1.173\n",
      "Epoch 15, Batch 1496/1871: Loss = 1.177\n",
      "Epoch 15, Batch 1683/1871: Loss = 1.176\n",
      "Epoch 15, Batch 1870/1871: Loss = 1.174\n",
      "Epoch: 15 loss: 1.174\n",
      "Epoch 16, Batch 187/1871: Loss = 1.193\n",
      "Epoch 16, Batch 374/1871: Loss = 1.175\n",
      "Epoch 16, Batch 561/1871: Loss = 1.179\n",
      "Epoch 16, Batch 748/1871: Loss = 1.184\n",
      "Epoch 16, Batch 935/1871: Loss = 1.180\n",
      "Epoch 16, Batch 1122/1871: Loss = 1.179\n",
      "Epoch 16, Batch 1309/1871: Loss = 1.182\n",
      "Epoch 16, Batch 1496/1871: Loss = 1.175\n",
      "Epoch 16, Batch 1683/1871: Loss = 1.174\n",
      "Epoch 16, Batch 1870/1871: Loss = 1.173\n",
      "Epoch: 16 loss: 1.173\n",
      "Epoch 17, Batch 187/1871: Loss = 1.193\n",
      "Epoch 17, Batch 374/1871: Loss = 1.167\n",
      "Epoch 17, Batch 561/1871: Loss = 1.169\n",
      "Epoch 17, Batch 748/1871: Loss = 1.178\n",
      "Epoch 17, Batch 935/1871: Loss = 1.178\n",
      "Epoch 17, Batch 1122/1871: Loss = 1.179\n",
      "Epoch 17, Batch 1309/1871: Loss = 1.172\n",
      "Epoch 17, Batch 1496/1871: Loss = 1.173\n",
      "Epoch 17, Batch 1683/1871: Loss = 1.176\n",
      "Epoch 17, Batch 1870/1871: Loss = 1.174\n",
      "Epoch: 17 loss: 1.173\n",
      "Epoch 18, Batch 187/1871: Loss = 1.153\n",
      "Epoch 18, Batch 374/1871: Loss = 1.165\n",
      "Epoch 18, Batch 561/1871: Loss = 1.162\n",
      "Epoch 18, Batch 748/1871: Loss = 1.168\n",
      "Epoch 18, Batch 935/1871: Loss = 1.166\n",
      "Epoch 18, Batch 1122/1871: Loss = 1.167\n",
      "Epoch 18, Batch 1309/1871: Loss = 1.172\n",
      "Epoch 18, Batch 1496/1871: Loss = 1.171\n",
      "Epoch 18, Batch 1683/1871: Loss = 1.170\n",
      "Epoch 18, Batch 1870/1871: Loss = 1.171\n",
      "Epoch: 18 loss: 1.171\n",
      "Epoch 19, Batch 187/1871: Loss = 1.140\n",
      "Epoch 19, Batch 374/1871: Loss = 1.151\n",
      "Epoch 19, Batch 561/1871: Loss = 1.154\n",
      "Epoch 19, Batch 748/1871: Loss = 1.165\n",
      "Epoch 19, Batch 935/1871: Loss = 1.172\n",
      "Epoch 19, Batch 1122/1871: Loss = 1.174\n",
      "Epoch 19, Batch 1309/1871: Loss = 1.171\n",
      "Epoch 19, Batch 1496/1871: Loss = 1.171\n",
      "Epoch 19, Batch 1683/1871: Loss = 1.174\n",
      "Epoch 19, Batch 1870/1871: Loss = 1.173\n",
      "Epoch: 19 loss: 1.173\n",
      "Epoch 20, Batch 187/1871: Loss = 1.182\n",
      "Epoch 20, Batch 374/1871: Loss = 1.179\n",
      "Epoch 20, Batch 561/1871: Loss = 1.178\n",
      "Epoch 20, Batch 748/1871: Loss = 1.173\n",
      "Epoch 20, Batch 935/1871: Loss = 1.177\n",
      "Epoch 20, Batch 1122/1871: Loss = 1.176\n",
      "Epoch 20, Batch 1309/1871: Loss = 1.172\n",
      "Epoch 20, Batch 1496/1871: Loss = 1.177\n",
      "Epoch 20, Batch 1683/1871: Loss = 1.175\n",
      "Epoch 20, Batch 1870/1871: Loss = 1.174\n",
      "Epoch: 20 loss: 1.174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Batch 187/1871: Loss = 1.128\n",
      "Epoch 21, Batch 374/1871: Loss = 1.145\n",
      "Epoch 21, Batch 561/1871: Loss = 1.158\n",
      "Epoch 21, Batch 748/1871: Loss = 1.158\n",
      "Epoch 21, Batch 935/1871: Loss = 1.160\n",
      "Epoch 21, Batch 1122/1871: Loss = 1.167\n",
      "Epoch 21, Batch 1309/1871: Loss = 1.164\n",
      "Epoch 21, Batch 1496/1871: Loss = 1.164\n",
      "Epoch 21, Batch 1683/1871: Loss = 1.169\n",
      "Epoch 21, Batch 1870/1871: Loss = 1.169\n",
      "Epoch: 21 loss: 1.170\n",
      "Epoch 22, Batch 187/1871: Loss = 1.159\n",
      "Epoch 22, Batch 374/1871: Loss = 1.165\n",
      "Epoch 22, Batch 561/1871: Loss = 1.163\n",
      "Epoch 22, Batch 748/1871: Loss = 1.172\n",
      "Epoch 22, Batch 935/1871: Loss = 1.176\n",
      "Epoch 22, Batch 1122/1871: Loss = 1.178\n",
      "Epoch 22, Batch 1309/1871: Loss = 1.176\n",
      "Epoch 22, Batch 1496/1871: Loss = 1.176\n",
      "Epoch 22, Batch 1683/1871: Loss = 1.176\n",
      "Epoch 22, Batch 1870/1871: Loss = 1.173\n",
      "Epoch: 22 loss: 1.175\n",
      "Epoch 23, Batch 187/1871: Loss = 1.176\n",
      "Epoch 23, Batch 374/1871: Loss = 1.177\n",
      "Epoch 23, Batch 561/1871: Loss = 1.186\n",
      "Epoch 23, Batch 748/1871: Loss = 1.179\n",
      "Epoch 23, Batch 935/1871: Loss = 1.177\n",
      "Epoch 23, Batch 1122/1871: Loss = 1.175\n",
      "Epoch 23, Batch 1309/1871: Loss = 1.178\n",
      "Epoch 23, Batch 1496/1871: Loss = 1.176\n",
      "Epoch 23, Batch 1683/1871: Loss = 1.174\n",
      "Epoch 23, Batch 1870/1871: Loss = 1.173\n",
      "Epoch: 23 loss: 1.173\n",
      "Epoch 24, Batch 187/1871: Loss = 1.190\n",
      "Epoch 24, Batch 374/1871: Loss = 1.175\n",
      "Epoch 24, Batch 561/1871: Loss = 1.164\n",
      "Epoch 24, Batch 748/1871: Loss = 1.166\n",
      "Epoch 24, Batch 935/1871: Loss = 1.171\n",
      "Epoch 24, Batch 1122/1871: Loss = 1.170\n",
      "Epoch 24, Batch 1309/1871: Loss = 1.175\n",
      "Epoch 24, Batch 1496/1871: Loss = 1.175\n",
      "Epoch 24, Batch 1683/1871: Loss = 1.178\n",
      "Epoch 24, Batch 1870/1871: Loss = 1.175\n",
      "Epoch: 24 loss: 1.175\n",
      "Epoch 25, Batch 187/1871: Loss = 1.168\n",
      "Epoch 25, Batch 374/1871: Loss = 1.188\n",
      "Epoch 25, Batch 561/1871: Loss = 1.173\n",
      "Epoch 25, Batch 748/1871: Loss = 1.165\n",
      "Epoch 25, Batch 935/1871: Loss = 1.169\n",
      "Epoch 25, Batch 1122/1871: Loss = 1.173\n",
      "Epoch 25, Batch 1309/1871: Loss = 1.170\n",
      "Epoch 25, Batch 1496/1871: Loss = 1.173\n",
      "Epoch 25, Batch 1683/1871: Loss = 1.170\n",
      "Epoch 25, Batch 1870/1871: Loss = 1.172\n",
      "Epoch: 25 loss: 1.172\n",
      "Finished Training\n",
      "Accuracy: 0.60\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.03      0.06       453\n",
      "           2       0.00      0.00      0.00        77\n",
      "           3       0.00      0.00      0.00        73\n",
      "           4       0.00      0.00      0.00       169\n",
      "           5       0.59      1.00      0.74      1099\n",
      "\n",
      "    accuracy                           0.60      1871\n",
      "   macro avg       0.32      0.21      0.16      1871\n",
      "weighted avg       0.59      0.60      0.45      1871\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pepperdine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pepperdine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pepperdine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 1.190\n",
      "Epoch: 2 loss: 1.172\n",
      "Epoch: 3 loss: 1.176\n",
      "Epoch: 4 loss: 1.177\n",
      "Epoch: 5 loss: 1.179\n",
      "Epoch: 6 loss: 1.175\n",
      "Epoch: 7 loss: 1.179\n",
      "Epoch: 8 loss: 1.176\n",
      "Epoch: 9 loss: 1.174\n",
      "Epoch: 10 loss: 1.173\n",
      "Epoch: 11 loss: 1.178\n",
      "Epoch: 12 loss: 1.173\n",
      "Epoch: 13 loss: 1.175\n",
      "Epoch: 14 loss: 1.176\n",
      "Epoch: 15 loss: 1.172\n",
      "Epoch: 16 loss: 1.174\n",
      "Epoch: 17 loss: 1.173\n",
      "Epoch: 18 loss: 1.179\n",
      "Epoch: 19 loss: 1.179\n",
      "Epoch: 20 loss: 1.177\n",
      "Epoch: 21 loss: 1.178\n",
      "Epoch: 22 loss: 1.179\n",
      "Epoch: 23 loss: 1.180\n",
      "Epoch: 24 loss: 1.180\n",
      "Epoch: 25 loss: 1.177\n",
      "Finished Training\n",
      "Accuracy: 0.59\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       453\n",
      "           2       0.00      0.00      0.00        77\n",
      "           3       0.00      0.00      0.00        73\n",
      "           4       0.00      0.00      0.00       169\n",
      "           5       0.59      1.00      0.74      1099\n",
      "\n",
      "    accuracy                           0.59      1871\n",
      "   macro avg       0.12      0.20      0.15      1871\n",
      "weighted avg       0.35      0.59      0.43      1871\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pepperdine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pepperdine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pepperdine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
