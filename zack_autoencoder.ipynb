{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tW_BPubIngrs",
        "outputId": "542052d0-e02e-4921-ccfc-8217470a9c49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     24\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mA\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autocast, GradScaler\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'albumentations'"
          ]
        }
      ],
      "source": [
        "#importing all the packages\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn import functional as F\n",
        "from skimage import io, transform\n",
        "from torch.optim import lr_scheduler\n",
        "from skimage.transform import AffineTransform, warp\n",
        "from tqdm import tqdm\n",
        "device = torch.device('cuda')\n",
        "import albumentations as A\n",
        "from torch.cuda.amp import autocast, GradScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create dataset class to return each batch\n",
        "from matplotlib import pyplot as plt\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "class SurfAutoencoder(Dataset):\n",
        "    def __init__(self, csv_file, augment=False):\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.augment = augment\n",
        "        self.transform = transforms.ToTensor()\n",
        "\n",
        "        if self.augment:\n",
        "            self.augmentation_transform = A.Compose([\n",
        "                A.Rotate(limit = 90, p=1)\n",
        "            ])\n",
        "        else:\n",
        "            self.augmentation_transform = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        first_image = cv2.imread(self.annotations.iloc[index, 0])\n",
        "        if self.augmentation_transform is not None:\n",
        "            augmented = self.augmentation_transform(image=first_image)\n",
        "            first_image = augmented[\"image\"]\n",
        "\n",
        "        first_image = self.transform(first_image)\n",
        "\n",
        "        return first_image\n"
      ],
      "metadata": {
        "id": "nKEgxw52nkKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train = SurfAutoencoder(csv_file = 'replace-with-training-.csv',augment = True)  #todo create csv file and put path here train.csv, val.csv\n",
        "val = SurfAutoencoder(csv_file = 'replace-with-validation-.csv',augment = False)\n",
        "test = SurfAutoencoder(csv_file = 'replace-with-test-.csv',augment = False)\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(dataset = train, batch_size = batch_size,shuffle = True)\n",
        "val_loader =DataLoader(dataset =  val, batch_size = batch_size,shuffle = False)\n",
        "test_loader =DataLoader(dataset =  test, batch_size = batch_size,shuffle = False)\n",
        "\n",
        "\n",
        "print(train.__getitem__(0))"
      ],
      "metadata": {
        "id": "z_jX7iYvn0Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 8, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 4, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(4, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(8, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "input = torch.randn(1, 3, 224, 224)\n",
        "model = Autoencoder()\n",
        "output = model(input)\n",
        "print(output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT3_Ap4CoRZY",
        "outputId": "768d7d8d-5075-47c3-a152-1cc0cc8a731e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "autoencoder = Autoencoder()\n",
        "autoencoder.to(device)\n",
        "\n",
        "learning_rate = 0.001\n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    autoencoder.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, _ in train_loader:\n",
        "        images = images.to(device)\n",
        "        reconstructions = autoencoder(images)\n",
        "        loss = criterion(reconstructions, images)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    autoencoder.eval()\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, _ in val_loader:\n",
        "            images = images.to(device)\n",
        "            reconstructions = autoencoder(images)\n",
        "            loss = criterion(reconstructions, images)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "autoencoder.eval()\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for images, _ in test_loader:\n",
        "        images = images.to(device)\n",
        "        reconstructions = autoencoder(images)\n",
        "        loss = criterion(reconstructions, images)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "APrHnmhxoPLh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}